{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "from t5.dataset import load_spider_datasets, DatasetIterator\n",
    "from t5.model import BaseModel, set_train_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login --token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"t5-base\"\n",
    "technique = \"fine_tuned\"\n",
    "version = 1\n",
    "checkpoint = 2190\n",
    "\n",
    "folder_name = f\"{model_name}_{technique}_{version}\"\n",
    "train_path = f\"results/{folder_name}\"\n",
    "model_path = train_path + f'/{folder_name}'\n",
    "last_check_point = train_path + f'/checkpoint-{checkpoint}'\n",
    "\n",
    "hug_model_name = \"RoxyRong/t5_base_finetuned_15\"\n",
    "\n",
    "print(\"train_path:\", train_path)\n",
    "print(\"model_path:\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"RoxyRong/t5_base_finetuned_test_5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spider, others_spider, dev_spider = load_spider_datasets()\n",
    "train_spider = train_spider.iloc[np.random.permutation(train_spider.index)].reset_index(drop=True)\n",
    "others_spider = train_spider.iloc[np.random.permutation(others_spider.index)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_load_at_once = 100\n",
    "\n",
    "train_data_iterator = DatasetIterator(\n",
    "    df=train_spider,\n",
    "    tokenizer=tokenizer,\n",
    "    max_load_at_once=max_load_at_once,\n",
    ")\n",
    "\n",
    "valid_data_iterator = DatasetIterator(\n",
    "    df=others_spider,\n",
    "    tokenizer=tokenizer,\n",
    "    max_load_at_once=max_load_at_once,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = set_train_arguments(\n",
    "    train_path=train_path,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = BaseModel(\n",
    "    model=model,\n",
    "    hug_model_name=  hug_model_name,\n",
    "    train_data_iterator = train_data_iterator,\n",
    "    valid_data_iterator = valid_data_iterator,\n",
    "    seq2seq_train_args = args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train from scratch\n",
    "trainer.train()\n",
    "\n",
    "# train from checkpoint\n",
    "trainer.train_from_checkpoint(last_check_point=last_check_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model_save(model_path=model_path)\n",
    "trainer.model_upload()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
