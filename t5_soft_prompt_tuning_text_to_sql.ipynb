{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roxyrong/w266_project/blob/main/t5_soft_prompt_tuning_text_to_sql.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZJNzUdXJLqb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install accelerate -U\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA6NMt2BQ1pY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3af21e5-eb00-466c-cd91-cea46705ac16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrxT7ulwR19d",
        "outputId": "8a4e4d92-44fd-4f94-b44d-19877cb8b4a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Github/w266_project\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Github/w266_project\n",
        "\n",
        "import sys\n",
        "project_path = '/content/drive/MyDrive/Github/w266_project'\n",
        "sys.path.append(project_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPQuxy9_H0HP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Dict, List\n",
        "import subprocess\n",
        "import collections\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "from third_party.soft_prompt_tuning.soft_embedding import SoftEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cEvN9aDomCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e6f6577-a50a-4a83-f88f-366030c48383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# for evaluation\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zva6eKoPH7j1"
      },
      "outputs": [],
      "source": [
        "# datasets\n",
        "with open('spider/train_spider.json', 'r') as f:\n",
        "    train_spider = pd.read_json(f)\n",
        "with open('spider/train_others.json', 'r') as f:\n",
        "    others_spider = pd.read_json(f)\n",
        "with open('spider/dev.json', 'r') as f:\n",
        "    dev_spider = pd.read_json(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iYPW9ODH80T"
      },
      "outputs": [],
      "source": [
        "# load schema for all tables\n",
        "with open('spider/tables.json', 'r') as f:\n",
        "    schema_df = pd.read_json(f)\n",
        "\n",
        "# db_dir = f\"spider/database\"\n",
        "# schema_dict = {}\n",
        "# column_names_dict = {}\n",
        "# for idx, row in schema_df.iterrows():\n",
        "#     db = row['db_id']\n",
        "#     db_path = os.path.join(db_dir, db, db + \".sqlite\")\n",
        "#     schema = str(get_schema(db_path))\n",
        "#     schema_dict[db] = schema\n",
        "#     column_name = json.loads(schema.replace(\"'\", \"\\\"\"))\n",
        "#     column_names_dict[db]= {\"table_id\": list(column_name.keys()), \"column_name\": schema}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE6FOe8wQ4QV"
      },
      "outputs": [],
      "source": [
        "def _get_schema_string(table_json):\n",
        "  \"\"\"Returns the schema serialized as a string.\"\"\"\n",
        "  table_id_to_column_names = collections.defaultdict(list)\n",
        "  for table_id, name in table_json[\"column_names_original\"]:\n",
        "    table_id_to_column_names[table_id].append(name.lower())\n",
        "  tables = table_json[\"table_names_original\"]\n",
        "\n",
        "  table_strings = []\n",
        "  for table_id, table_name in enumerate(tables):\n",
        "    column_names = table_id_to_column_names[table_id]\n",
        "    table_string = \" | %s : %s\" % (table_name.lower(), \" , \".join(column_names))\n",
        "    table_strings.append(table_string)\n",
        "\n",
        "  return \"\".join(table_strings)\n",
        "\n",
        "schema_dict = {}\n",
        "for idx, row in schema_df.iterrows():\n",
        "  db_id = row['db_id']\n",
        "  schema = _get_schema_string(row)\n",
        "  schema_dict[db_id] = schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZPZvrTWH-LC"
      },
      "outputs": [],
      "source": [
        "# shuffle the dataset\n",
        "\n",
        "train_spider = train_spider.iloc[np.random.permutation(train_spider.index)].reset_index(drop=True)\n",
        "others_spider = train_spider.iloc[np.random.permutation(others_spider.index)].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ja3AjYzL0Ao"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVAWRmLmSV0i"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "model_name = \"google/t5-base-lm-adapt\"\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "size = 32128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "an2hxxSuH_6g"
      },
      "outputs": [],
      "source": [
        "# construct prompt\n",
        "\n",
        "prefix = 'translate English to SQL:'\n",
        "\n",
        "train_spider['schema'] = train_spider['db_id'].map(schema_dict)\n",
        "train_spider['prompt'] = prefix + train_spider['question'] + '\\nDatabse schema is ' + train_spider['schema']\n",
        "others_spider['schema'] = others_spider['db_id'].map(schema_dict)\n",
        "others_spider['prompt'] = prefix + others_spider['question'] + '\\nDatabse schema is ' + others_spider['schema']\n",
        "dev_spider['schema'] = dev_spider['db_id'].map(schema_dict)\n",
        "dev_spider['prompt'] = prefix + dev_spider['question'] + '\\nDatabse schema is ' + dev_spider['schema']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AUfmPPLXmNs"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rpj0cCWHS7q5"
      },
      "outputs": [],
      "source": [
        "# soft prompt setup\n",
        "n_tokens = 20\n",
        "initialize_from_vocab = True\n",
        "\n",
        "s_wte = SoftEmbedding(model.get_input_embeddings(),\n",
        "                      n_tokens=n_tokens,\n",
        "                      initialize_from_vocab=initialize_from_vocab)\n",
        "model.set_input_embeddings(s_wte)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hizv4iaEIg1T"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(text_pair, tokenizer, max_length=128):\n",
        "    orig_text, target_text = text_pair\n",
        "    orig_encoded = tokenizer.batch_encode_plus(\n",
        "        [orig_text],\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    # orig_input_ids = orig_encoded['input_ids'][0]\n",
        "    # orig_attention_mask = orig_encoded['attention_mask'][0]\n",
        "\n",
        "    orig_input_ids = torch.cat([torch.full((1,n_tokens), size),\n",
        "                                orig_encoded['input_ids']], 1)[0]\n",
        "\n",
        "    orig_attention_mask = torch.cat([torch.full((1,n_tokens), 1),\n",
        "                                     orig_encoded['attention_mask']], 1)[0]\n",
        "\n",
        "    target_encoded = tokenizer.batch_encode_plus(\n",
        "        [target_text],\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    label_ids = target_encoded['input_ids'][0]\n",
        "\n",
        "    return {'input_ids': orig_input_ids,\n",
        "            'attention_mask': orig_attention_mask,\n",
        "            'labels': label_ids}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9IiV9LXIkkD"
      },
      "outputs": [],
      "source": [
        "class TranslationDataIterator:\n",
        "\n",
        "    def __init__(self,\n",
        "                 df,\n",
        "                 tokenizer,\n",
        "                 max_load_at_once,\n",
        "                 max_length=128,\n",
        "                 shuffle=True):\n",
        "\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.n_examples = len(df)\n",
        "        self.max_load_at_once = max_load_at_once\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        # Initialize row order, call on_epoch_end to shuffle row indices\n",
        "        self.row_order = np.arange(1, self.n_examples+1)\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        # Load first chunk of max_load_at_once examples\n",
        "        self.df_curr_loaded = self._load_next_chunk(0)\n",
        "        self.curr_idx_in_load = 0\n",
        "\n",
        "    def _load_next_chunk(self, idx):\n",
        "        load_start = idx\n",
        "        load_end = idx + self.max_load_at_once\n",
        "\n",
        "        # Indices to skip are the ones in the shuffled row_order before and\n",
        "        # after the chunk we'll use for this chunk\n",
        "        self.df_curr_loaded = self.df.iloc[load_start:load_end].sample(frac=1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_examples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.df_curr_loaded is None or self.curr_idx_in_load >= len(self.df_curr_loaded):\n",
        "            self._load_next_chunk(idx)\n",
        "            self.curr_idx_in_load = 0\n",
        "\n",
        "        text_pair = self.df_curr_loaded[['prompt', 'query']].values.astype(str)[self.curr_idx_in_load]\n",
        "        self.curr_idx_in_load += 1\n",
        "\n",
        "        item_data = preprocess_data(\n",
        "            text_pair,\n",
        "            self.tokenizer,\n",
        "            self.max_length\n",
        "        )\n",
        "\n",
        "        return item_data\n",
        "\n",
        "    def __call__(self):\n",
        "        for i in range(self.__len__()):\n",
        "            yield self.__getitem__(i)\n",
        "\n",
        "            if i == self.__len__()-1:\n",
        "                self.on_epoch_end()\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.row_order = list(np.random.permutation(self.row_order))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmEu_mBcL8zW"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArkzDDRD4u2H"
      },
      "outputs": [],
      "source": [
        "folder_name = f\"{model_name}-softprompt_2\"\n",
        "train_path = f\"{project_path}/{folder_name}\"\n",
        "model_path = train_path + f'/{model_name}-softprompt_2'\n",
        "# last_check_point = f\"{project_path}/t5-base-finetuned-spider_2/checkpoint-10500\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ4pWEZ8ImOU"
      },
      "outputs": [],
      "source": [
        "max_length = 512\n",
        "max_load_at_once = 100\n",
        "\n",
        "train_data_iterator = TranslationDataIterator(\n",
        "    df=train_spider,\n",
        "    tokenizer=tokenizer,\n",
        "    max_load_at_once=max_load_at_once,\n",
        "    max_length=max_length\n",
        ")\n",
        "\n",
        "valid_data_iterator = TranslationDataIterator(\n",
        "    df=others_spider,\n",
        "    tokenizer=tokenizer,\n",
        "    max_load_at_once=max_load_at_once,\n",
        "    max_length=max_length\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7r9oQcVInfU"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    train_path,\n",
        "    evaluation_strategy='epoch',\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWGwZQFhIo0_"
      },
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_data_iterator,\n",
        "    eval_dataset=valid_data_iterator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gr-QshK9IqBj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "7693cbbe-e583-4223-a69e-1ef61e140ede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1314' max='1314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1314/1314 20:41, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>35.914825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>32.421400</td>\n",
              "      <td>35.835030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>32.407900</td>\n",
              "      <td>35.808407</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1314, training_loss=32.402670757229835, metrics={'train_runtime': 1245.131, 'train_samples_per_second': 16.866, 'train_steps_per_second': 1.055, 'total_flos': 1.4942649028608e+16, 'train_loss': 32.402670757229835, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# start from scratch\n",
        "trainer.train()\n",
        "\n",
        "# start from a checkpoint\n",
        "# trainer.train(resume_from_checkpoint= last_check_point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz6CbDO2Vd6k"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cp4TIpG27hA"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwK5m6fAZ_vM",
        "outputId": "d7ee998a-d48d-4a7f-a452-682c833af20b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/Github/w266_project/t5-base-softprompt-spider/t5-base-softprompt_2 were not used when initializing T5ForConditionalGeneration: ['decoder.embed_tokens.learned_embedding', 'decoder.embed_tokens.wte.weight', 'encoder.embed_tokens.learned_embedding', 'shared.learned_embedding', 'encoder.embed_tokens.wte.weight', 'shared.wte.weight']\n",
            "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "finetune_model = T5ForConditionalGeneration.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4perd2zXmzG"
      },
      "outputs": [],
      "source": [
        "# evaluate\n",
        "max_length = 128\n",
        "\n",
        "inputs = tokenizer.batch_encode_plus(\n",
        "        list(dev_spider['prompt']),\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "output_tokens = finetune_model.generate(\n",
        "    input_ids=inputs[\"input_ids\"],\n",
        "    attention_mask=inputs[\"attention_mask\"],\n",
        "    max_length=128\n",
        ")\n",
        "\n",
        "outputs = [tokenizer.decode(i, skip_special_tokens=True) for i in output_tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3r5R4IuOgI7r"
      },
      "outputs": [],
      "source": [
        "with open(f'{folder_name}/predicted_result.txt', 'w') as f:\n",
        "    for idx, output in enumerate(outputs):\n",
        "        db_id = dev_spider.iloc[idx]['db_id']\n",
        "        f.write(output + '\\t' + db_id + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nv7ZpIoaajtw"
      },
      "outputs": [],
      "source": [
        "# evaluate results\n",
        "eval_path = f\"third_party/spider/evaluation.py\"\n",
        "gold = f\"third_party/spider/evaluation_examples/gold_example.txt\"\n",
        "pred = f\"{folder_name}/predicted_result.txt\"\n",
        "db_dir = f\"spider/database\"\n",
        "table = f\"spider/tables.json\"\n",
        "etype = \"all\"\n",
        "\n",
        "cmd_str = f\"python3 \\\"{eval_path}\\\" --gold \\\"{gold}\\\" --pred \\\"{pred}\\\" --db \\\"{db_dir}\\\" --table \\\"{table}\\\" --etype {etype} \"\n",
        "result = subprocess.run(cmd_str, shell=True, capture_output=True, text=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh4yyml1jMbY",
        "outputId": "370892a3-d32c-467e-ec01-6694a9e1a4b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('                     easy                 medium               '\n",
            " 'hard                 extra                all                 \\n'\n",
            " 'count                250                  440                  '\n",
            " '174                  170                  1034                \\n'\n",
            " '=====================   EXECUTION ACCURACY     =====================\\n'\n",
            " 'execution            0.028                0.007                '\n",
            " '0.000                0.000                0.010               \\n'\n",
            " '\\n'\n",
            " '====================== EXACT MATCHING ACCURACY =====================\\n'\n",
            " 'exact match          0.044                0.007                '\n",
            " '0.000                0.000                0.014               \\n'\n",
            " '\\n'\n",
            " '---------------------PARTIAL MATCHING ACCURACY----------------------\\n'\n",
            " 'select               0.551                0.245                '\n",
            " '0.583                0.200                0.420               \\n'\n",
            " 'select(no AGG)       0.673                0.245                '\n",
            " '0.583                0.400                0.473               \\n'\n",
            " 'where                0.214                0.152                '\n",
            " '0.000                0.000                0.129               \\n'\n",
            " 'where(no OP)         0.286                0.242                '\n",
            " '0.190                0.000                0.235               \\n'\n",
            " 'group(no Having)     0.000                0.000                '\n",
            " '0.000                1.000                1.000               \\n'\n",
            " 'group                0.000                0.000                '\n",
            " '0.000                1.000                1.000               \\n'\n",
            " 'order                0.000                0.000                '\n",
            " '0.000                1.000                0.500               \\n'\n",
            " 'and/or               1.000                0.902                '\n",
            " '0.893                0.869                0.919               \\n'\n",
            " 'IUEN                 0.000                0.000                '\n",
            " '0.000                0.000                0.000               \\n'\n",
            " 'keywords             0.393                0.242                '\n",
            " '0.095                0.250                0.256               \\n'\n",
            " '---------------------- PARTIAL MATCHING RECALL ----------------------\\n'\n",
            " 'select               0.108                0.030                '\n",
            " '0.080                0.006                0.053               \\n'\n",
            " 'select(no AGG)       0.132                0.030                '\n",
            " '0.080                0.012                0.060               \\n'\n",
            " 'where                0.056                0.028                '\n",
            " '0.000                0.000                0.023               \\n'\n",
            " 'where(no OP)         0.074                0.045                '\n",
            " '0.043                0.000                0.042               \\n'\n",
            " 'group(no Having)     0.000                0.000                '\n",
            " '0.000                0.013                0.004               \\n'\n",
            " 'group                0.000                0.000                '\n",
            " '0.000                0.013                0.004               \\n'\n",
            " 'order                0.000                0.000                '\n",
            " '0.000                0.012                0.004               \\n'\n",
            " 'and/or               1.000                0.992                '\n",
            " '0.968                0.986                0.989               \\n'\n",
            " 'IUEN                 0.000                0.000                '\n",
            " '0.000                0.000                0.000               \\n'\n",
            " 'keywords             0.073                0.022                '\n",
            " '0.011                0.006                0.025               \\n'\n",
            " '---------------------- PARTIAL MATCHING F1 --------------------------\\n'\n",
            " 'select               0.181                0.053                '\n",
            " '0.141                0.011                0.094               \\n'\n",
            " 'select(no AGG)       0.221                0.053                '\n",
            " '0.141                0.023                0.106               \\n'\n",
            " 'where                0.088                0.047                '\n",
            " '1.000                1.000                0.039               \\n'\n",
            " 'where(no OP)         0.118                0.076                '\n",
            " '0.071                1.000                0.071               \\n'\n",
            " 'group(no Having)     1.000                1.000                '\n",
            " '1.000                0.025                0.007               \\n'\n",
            " 'group                1.000                1.000                '\n",
            " '1.000                0.025                0.007               \\n'\n",
            " 'order                1.000                1.000                '\n",
            " '1.000                0.024                0.008               \\n'\n",
            " 'and/or               1.000                0.945                '\n",
            " '0.929                0.924                0.953               \\n'\n",
            " 'IUEN                 1.000                1.000                '\n",
            " '1.000                1.000                1.000               \\n'\n",
            " 'keywords             0.124                0.040                '\n",
            " '0.021                0.011                0.046               \\n')\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "pprint.pprint(result.stdout[-4633:])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}