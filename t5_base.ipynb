{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roxyrong/anaconda3/envs/xlang/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)ve/main/spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 10.1MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 1.79kB [00:00, 2.78MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 25.0/25.0 [00:00<00:00, 13.7kB/s]\n",
      "Downloading (…)lve/main/config.json: 1.23kB [00:00, 1.78MB/s]\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.19G/1.19G [00:29<00:00, 40.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# information about the cross-domain tables\n",
    "with open('spider/tables.json', 'r') as f:\n",
    "    schema_df = pd.read_json(f)\n",
    "\n",
    "# datasets\n",
    "with open('spider/train_spider.json', 'r') as f:\n",
    "    train_spider = pd.read_json(f)\n",
    "with open('spider/train_others.json', 'r') as f:\n",
    "    others_spider = pd.read_json(f)\n",
    "with open('spider/dev.json', 'r') as f:\n",
    "    dev_spider = pd.read_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['db_id', 'query', 'query_toks', 'query_toks_no_value', 'question',\n",
      "       'question_toks', 'sql'],\n",
      "      dtype='object') 7000\n",
      "Index(['db_id', 'query', 'query_toks', 'query_toks_no_value', 'question',\n",
      "       'question_toks', 'sql'],\n",
      "      dtype='object') 1659\n",
      "Index(['db_id', 'query', 'query_toks', 'query_toks_no_value', 'question',\n",
      "       'question_toks', 'sql'],\n",
      "      dtype='object') 1034\n",
      "Index(['column_names', 'column_names_original', 'column_types', 'db_id',\n",
      "       'foreign_keys', 'primary_keys', 'table_names', 'table_names_original'],\n",
      "      dtype='object') 166\n"
     ]
    }
   ],
   "source": [
    "print(train_spider.columns, len(train_spider))\n",
    "print(others_spider.columns, len(others_spider))\n",
    "print(dev_spider.columns, len(dev_spider))\n",
    "print(schema_df.columns, len(schema_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = []\n",
    "f_keys = []\n",
    "p_keys = []\n",
    "for index, row in schema_df.iterrows():\n",
    "    tables = row['table_names_original']\n",
    "    col_names = row['column_names_original']\n",
    "    col_types = row['column_types']\n",
    "    foreign_keys = row['foreign_keys']\n",
    "    primary_keys = row['primary_keys']\n",
    "    for col, col_type in zip(col_names, col_types):\n",
    "        index, col_name = col\n",
    "        if index == -1:\n",
    "            for table in tables:\n",
    "                schema.append([row['db_id'], table, '*', 'text'])\n",
    "        else:\n",
    "            schema.append([row['db_id'], tables[index], col_name, col_type])\n",
    "    for primary_key in primary_keys:\n",
    "        index, column = col_names[primary_key]\n",
    "        p_keys.append([row['db_id'], tables[index], column])\n",
    "    for foreign_key in foreign_keys:\n",
    "        first, second = foreign_key\n",
    "        first_index, first_column = col_names[first]\n",
    "        second_index, second_column = col_names[second]\n",
    "        f_keys.append([row['db_id'], tables[first_index], tables[second_index], first_column, second_column])\n",
    "spider_schema = pd.DataFrame(schema, columns=['Database name', ' Table Name', ' Field Name', ' Type'])\n",
    "spider_primary = pd.DataFrame(p_keys, columns=['Database name', 'Table Name', 'Primary Key'])\n",
    "spider_foreign = pd.DataFrame(f_keys,\n",
    "                    columns=['Database name', 'First Table Name', 'Second Table Name', 'First Table Foreign Key',\n",
    "                                'Second Table Foreign Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema: \n",
      "   Database name   Table Name      Field Name    Type\n",
      "0   perpetrator  perpetrator               *    text\n",
      "1   perpetrator       people               *    text\n",
      "2   perpetrator  perpetrator  Perpetrator_ID  number\n",
      "3   perpetrator  perpetrator       People_ID  number\n",
      "4   perpetrator  perpetrator            Date    text\n",
      "primary key: \n",
      "   Database name   Table Name     Primary Key\n",
      "0   perpetrator  perpetrator  Perpetrator_ID\n",
      "1   perpetrator       people       People_ID\n",
      "2     college_2    classroom        building\n",
      "3     college_2   department       dept_name\n",
      "4     college_2       course       course_id\n",
      "foreign key: \n",
      "   Database name First Table Name Second Table Name First Table Foreign Key  \\\n",
      "0   perpetrator      perpetrator            people               People_ID   \n",
      "1     college_2           course        department               dept_name   \n",
      "2     college_2       instructor        department               dept_name   \n",
      "3     college_2          section         classroom                building   \n",
      "4     college_2          section         classroom             room_number   \n",
      "\n",
      "  Second Table Foreign Key  \n",
      "0                People_ID  \n",
      "1                dept_name  \n",
      "2                dept_name  \n",
      "3                 building  \n",
      "4              room_number  \n"
     ]
    }
   ],
   "source": [
    "print('schema: \\n', spider_schema.head())\n",
    "print('primary key: \\n', spider_primary.head())\n",
    "print('foreign key: \\n', spider_foreign.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SELECT COUNT Singer(s) FROM table', 'SELECT COUNT Singer(s) FROM table', 'SELECT Name, Country, Age FROM table WHERE Order by Age = oldest to youngest', 'SELECT Name, Country, Age FROM table WHERE Age indescending order = singer', 'SELECT Age (Age) FROM table WHERE Country = france AND Minimum/Max. = minimum', 'SELECT Age (Age) FROM table WHERE Language = french AND Minimum/Maximum = all singers', 'SELECT Name and Release Year FROM table WHERE Name = youngest singer', 'SELECT Names and Release Year FROM table WHERE Name = youngest singer', 'SELECT Country FROM table WHERE Age > 20', 'SELECT Country FROM table WHERE Age > 20']\n"
     ]
    }
   ],
   "source": [
    "prefix = 'translate English to SQL:'\n",
    "\n",
    "dev_questions = list(dev_spider.iloc[:10]['question'])\n",
    "dev_questions = [prefix + q for q in dev_questions]\n",
    "\n",
    "inputs = tokenizer(dev_questions, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "output_tokens = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    max_length=64\n",
    ")\n",
    "\n",
    "outputs = [tokenizer.decode(i, skip_special_tokens=True) for i in output_tokens]\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use test-suite-sql-eval-master/evaluation.py for evaluation\n",
    "\n",
    "queries = list(dev_spider.iloc[:10]['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
