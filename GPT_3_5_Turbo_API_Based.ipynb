{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXnRoU6b4gFmloj0F2wqvK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roxyrong/w266_project/blob/main/GPT_3_5_Turbo_API_Based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChatGPT API-based SQL Generation\n",
        "\n"
      ],
      "metadata": {
        "id": "3x-_mwoxHqj2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PhIQT8JHpa6",
        "outputId": "51f1733a-c7b4-4d76-9139-8495c44c85aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n",
            "Requirement already satisfied: panel in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: bokeh<3.3.0,>=3.1.1 in /usr/local/lib/python3.10/dist-packages (from panel) (3.1.1)\n",
            "Requirement already satisfied: param>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from panel) (1.13.0)\n",
            "Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.10/dist-packages (from panel) (2.3.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from panel) (2023.7.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel) (3.0.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel) (2.0.2)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from panel) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from panel) (4.65.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel) (6.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from panel) (4.7.1)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from panel) (1.5.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh<3.3.0,>=3.1.1->panel) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh<3.3.0,>=3.1.1->panel) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from bokeh<3.3.0,>=3.1.1->panel) (1.22.4)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh<3.3.0,>=3.1.1->panel) (23.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh<3.3.0,>=3.1.1->panel) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh<3.3.0,>=3.1.1->panel) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh<3.3.0,>=3.1.1->panel) (6.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->panel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->panel) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bleach->panel) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel) (1.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel) (0.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->panel) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->panel) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->panel) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->panel) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh<3.3.0,>=3.1.1->panel) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "# Set up openai\n",
        "!pip install openai\n",
        "import openai\n",
        "openai.api_key=\"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\"\n",
        "\n",
        "# In case we want user interaction\n",
        "!pip install panel\n",
        "import panel as pn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up google drive for Spider\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N5dXtaOMjyo",
        "outputId": "7691524c-e019-482d-b2fa-411e2e70f329"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Github/w266_project\n",
        "\n",
        "import sys\n",
        "project_path = '/content/drive/MyDrive/Github/w266_project'\n",
        "sys.path.append(project_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-8LeLnnMsvH",
        "outputId": "eb1e3d58-424f-4a64-9005-22f88d4d84bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Github/w266_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional useful imports\n",
        "import os\n",
        "from typing import Dict, List\n",
        "import subprocess\n",
        "import collections\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import pprint\n",
        "import time\n",
        "from requests.exceptions import HTTPError"
      ],
      "metadata": {
        "id": "6-libl2-MxHU"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for evaluation\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuJDcI8PM6WM",
        "outputId": "3dc4c19d-9702-4d82-8a74-94e9ae29efd0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Spider Data"
      ],
      "metadata": {
        "id": "RtRiqJoeNEak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Spider datasets\n",
        "with open('spider/train_spider.json', 'r') as f:\n",
        "    train_spider = pd.read_json(f)\n",
        "with open('spider/train_others.json', 'r') as f:\n",
        "    others_spider = pd.read_json(f)\n",
        "with open('spider/dev.json', 'r') as f:\n",
        "    dev_spider = pd.read_json(f)"
      ],
      "metadata": {
        "id": "kJND7UQuNHGQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load schema for all tables\n",
        "with open('spider/tables.json', 'r') as f:\n",
        "    schema_df = pd.read_json(f)"
      ],
      "metadata": {
        "id": "Xw7qyNIcNUJG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Function to extract target schemas from Spider json to a dict\n",
        "# for training and prompt usage.\n",
        "def _get_schema_string(table_json):\n",
        "    \"\"\"Returns the schema serialized as a string.\"\"\"\n",
        "    table_id_to_column_names = collections.defaultdict(list)\n",
        "    for table_id, name in table_json[\"column_names_original\"]:\n",
        "        table_id_to_column_names[table_id].append(name.lower())\n",
        "        tables = table_json[\"table_names_original\"]\n",
        "\n",
        "    table_strings = []\n",
        "    for table_id, table_name in enumerate(tables):\n",
        "        column_names = table_id_to_column_names[table_id]\n",
        "        table_string = \" | %s : %s\" % (table_name.lower(), \" , \".join(column_names))\n",
        "        table_strings.append(table_string)\n",
        "\n",
        "    return \"\".join(table_strings)\n",
        "\n",
        "schema_dict = {}\n",
        "for idx, row in schema_df.iterrows():\n",
        "    db_id = row['db_id']\n",
        "    schema = _get_schema_string(row)\n",
        "    schema_dict[db_id] = schema"
      ],
      "metadata": {
        "id": "fKQchoklNWtW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up GPT API"
      ],
      "metadata": {
        "id": "4jF82LuZNJt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to call GPT API\n",
        "def text_to_sql(messages, temperature=0, retries=5, delay=5):\n",
        "    for i in range(retries):\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=messages,\n",
        "                temperature=temperature,\n",
        "            )\n",
        "            return response.choices[0].message[\"content\"]\n",
        "        except HTTPError as e:\n",
        "            if e.response.status_code == 502:  # Bad Gateway error\n",
        "                print(f\"Bad Gateway error, retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)  # wait for a while before retrying\n",
        "            else:\n",
        "                raise e  # if it's not a 502 error, re-raise the exception\n",
        "    raise Exception(\"Failed to process request after multiple attempts\")\n"
      ],
      "metadata": {
        "id": "vNZTlyPHHvTY"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with single prompt"
      ],
      "metadata": {
        "id": "hgRBgORtNN-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test prompt\n",
        "context = [ {'role':'system', 'content':\"\"\"\n",
        "Parse the question provided into SQL based on a provided schema which describes a database schema.\n",
        "Based on the provided schema, create an ANSI-92 SQL Query to answer the provided\n",
        "Return the answer as a SQL query ONLY. Do not include any additional explanation.\"\n",
        "\"\"\"} ]\n",
        "\n",
        "\n",
        "context.append( {'role':'system', 'content':\"\"\"\n",
        "Schema: | department : department_id , name , creation , ranking , budget_in_billions , num_employees | head : head_id , name , born_state , age | management : department_id , head_id , temporary_acting\n",
        "\"\"\"})\n",
        "\n",
        "context.append({'role':'user', 'content':\"Question:How many heads of the departments are older than 56?\"})\n",
        "\n"
      ],
      "metadata": {
        "id": "_dVxg8GxIOFs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ9k0cqEJCJP",
        "outputId": "98c98fd4-c367-45d6-94b8-e5665379c292"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': '\\nParse the question provided into SQL based on a provided schema which describes a database schema.\\nBased on the provided schema, create an ANSI-92 SQL Query to answer the provided\\nReturn the answer as a SQL query ONLY. Do not include any additional explanation.\"\\n'}, {'role': 'system', 'content': '\\nSchema: | department : department_id , name , creation , ranking , budget_in_billions , num_employees | head : head_id , name , born_state , age | management : department_id , head_id , temporary_acting\\n'}, {'role': 'user', 'content': 'Question:How many heads of the departments are older than 56?'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = text_to_sql(context)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mSKqTt2Ktsm",
        "outputId": "b9dc87ca-532f-49dd-b521-a7688397397d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT COUNT(*) FROM head WHERE age > 56;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build instruction-based prompt data set\n"
      ],
      "metadata": {
        "id": "I89BYrOyNjgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Each prompt in dev_spider will become a list of dictionaries to meet\n",
        "# API orientation to system / user of form [{'role': 'system'/'user', 'content':\"\"}]\n",
        "# [[{'role': 'system', 'content':prefix},{'role': 'system', 'content': '\\nSchema:},{'role': 'user', 'content': 'Question: ]\n",
        "\n",
        "def create_prompts(row):\n",
        "\n",
        "  instruction_prefix = {'role': 'system', 'content':\"\"\"\n",
        "  Parse the question provided into SQL based on a provided schema which describes a database schema.\n",
        "  Based on the provided schema, create an ANSI-92 SQL Query to answer the provided\n",
        "  Return the answer as a single line SQL query ONLY. Do not include any additional explanation.\"\n",
        "  \"\"\"}\n",
        "\n",
        "  instruction_infix = {'role': 'system', 'content':\"\"\"\n",
        "  Schema: \"\"\" + row['schema']}\n",
        "\n",
        "  instruction_postfix = {'role': 'user', 'content':\"\"\"\n",
        "  Question: \"\"\" + row['question']}\n",
        "\n",
        "  return[instruction_prefix, instruction_infix, instruction_postfix]\n"
      ],
      "metadata": {
        "id": "y1o_kqTHJ8Qh"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update dev_spider with prompts\n",
        "dev_spider['schema'] = dev_spider['db_id'].map(schema_dict)\n",
        "dev_spider['context'] = dev_spider.apply(create_prompts, axis=1)\n",
        "print(dev_spider['context'][500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWA3HKsyO8JG",
        "outputId": "4d5547ed-52b9-4fee-f549-ce8e22dd8a67"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': '\\n  Parse the question provided into SQL based on a provided schema which describes a database schema.\\n  Based on the provided schema, create an ANSI-92 SQL Query to answer the provided\\n  Return the answer as a single line SQL query ONLY. Do not include any additional explanation.\"\\n  '}, {'role': 'system', 'content': '\\n  Schema:  | battle : id , name , date , bulgarian_commander , latin_commander , result | ship : lost_in_battle , id , name , tonnage , ship_type , location , disposition_of_ship | death : caused_by_ship_id , id , note , killed , injured'}, {'role': 'user', 'content': '\\n  Question: What is the ship id and name that caused most total injuries?'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build few-shot based prompt data set"
      ],
      "metadata": {
        "id": "9zCCBMURJ9AA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ToDo as second test\n",
        "# Helper function to build prompts for testing.\n",
        "\n",
        "# def build_batch_prompts(prompt_type = \"instruction\"):\n",
        "#   if prompt_type == \"instruction\":\n",
        "#     pass\n",
        "#   elif prompt_type == \"few_shot\":\n",
        "#     two_shot_prefix = \"\"\"Context: | ref_document_types : document_type_code , document_type_description | roles : role_code , role_description | addresses : address_id , address_details | ref_document_status : document_status_code , document_status_description | ref_shipping_agents : shipping_agent_code , shipping_agent_name , shipping_agent_description | documents : document_id , document_status_code , document_type_code , shipping_agent_code , receipt_date , receipt_number , other_details | employees : employee_id , role_code , employee_name , other_details | document_drafts : document_id , draft_number , draft_details | draft_copies : document_id , draft_number , copy_number | circulation_history : document_id , draft_number , copy_number , employee_id | documents_mailed : document_id , mailed_to_address_id , mailing_date\n",
        "#            Question: Which employee has showed up in most circulation history documents. List the employee's name and the number of drafts and copies.\\n\"\n",
        "#            Answer: SELECT Employees.employee_name , count(*) FROM Employees JOIN Circulation_History ON Circulation_History.employee_id = Employees.employee_id GROUP BY Circulation_History.document_id , Circulation_History.draft_number , Circulation_History.copy_number ORDER BY count(*) DESC LIMIT 1;\n",
        "#            ###\n",
        "#            Context:| member : member_id , card_number , name , hometown , level | branch : branch_id , name , open_year , address_road , city , membership_amount | membership_register_branch : member_id , branch_id , register_year | purchase : member_id , branch_id , year , total_pounds\n",
        "#            Question: What are names for top three branches with most number of membership?\n",
        "#            Answer: SELECT name FROM branch ORDER BY membership_amount DESC LIMIT 3\n",
        "#            ###\n",
        "#            Context: \"\"\"\n",
        "\n",
        "#     two_shot_infix = \"\\n Question: \"\n",
        "#     two_shot_postfix = \"\\n Answer: \"\n",
        "\n",
        "#   dev_spider['schema'] = dev_spider['db_id'].map(schema_dict)\n",
        "#   dev_spider['prompt'] = fixed_few_shot_prefix + dev_spider['schema'] + fixed_few_shot_infix + dev_spider['question'] + fixed_few_shot_postfix\n",
        "\n"
      ],
      "metadata": {
        "id": "_56XXmYSLzEG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run test on dev data set"
      ],
      "metadata": {
        "id": "Vu_NtIMQNn73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ToDo - figure out how to do batch inference and manage API rate limiting\n",
        "# 1034 total prompts\n",
        "\n",
        "# Define a list to store outputs\n",
        "#outputs = []\n",
        "\n",
        "# Process each prompt individually\n",
        "for context in dev_spider['context'][900:]:\n",
        "  response = text_to_sql(context)\n",
        "  response = response.replace(\"\\n\", \" \")\n",
        "  #print(response)\n",
        "  outputs.append(response)\n"
      ],
      "metadata": {
        "id": "d7_YNS35Nqte"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "kye_AT7VNsaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model output to Drive\n",
        "model_name = \"GPT-3.5-turbo\"\n",
        "technique = \"pretrained\"\n",
        "version = 1\n",
        "inference_model = \"GPT-3.5-turbo\"\n",
        "\n",
        "folder_name = f\"{model_name}_{technique}_{version}\"\n",
        "# train_path = f\"results/{folder_name}\"\n",
        "# model_path = train_path + f'/{folder_name}'\n",
        "# last_check_point = train_path + f'/checkpoint-2190'\n",
        "result_path = f'results/{folder_name}/predicted_result_{inference_model}_{version}.txt'\n",
        "\n",
        "\n",
        "# print(\"train_path:\", train_path)\n",
        "# print(\"model_path:\", model_path)\n",
        "print(\"result_path:\", result_path)\n",
        "\n",
        "with open(result_path, 'w', encoding='utf-8') as f:\n",
        "    for idx, output in enumerate(outputs):\n",
        "        db_id = dev_spider.iloc[idx]['db_id']\n",
        "        f.write(output + '\\t' + db_id + '\\n')"
      ],
      "metadata": {
        "id": "oFpkUIcONumR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d38b5b-252f-4503-ce88-ff51dc146915"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result_path: results/GPT-3.5-turbo_pretrained_1/predicted_result_GPT-3.5-turbo_1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uSelq145dNU8",
        "outputId": "811e2f2d-cd5a-4fa6-e561-02efcc3075ef"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Github/w266_project'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate results\n",
        "eval_path = f\"third_party/spider/evaluation.py\"\n",
        "gold = f\"third_party/spider/evaluation_examples/gold_example.txt\"\n",
        "pred = f\"results/GPT-3.5-turbo_pretrained_1/predicted_result_GPT-3.5-turbo_1.txt\"\n",
        "db_dir = f\"spider/database\"\n",
        "table = f\"spider/tables.json\"\n",
        "etype = \"all\"\n",
        "\n",
        "cmd_str = f\"python3 \\\"{eval_path}\\\" --gold \\\"{gold}\\\" --pred \\\"{pred}\\\" --db \\\"{db_dir}\\\" --table \\\"{table}\\\" --etype {etype} \"\n",
        "result = subprocess.run(cmd_str, shell=True, capture_output=True, text=True)"
      ],
      "metadata": {
        "id": "tb4XSqXeN54T"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print results\n",
        "pp = pprint.PrettyPrinter(width=160)\n",
        "pp.pprint(result.stdout[-4633:])\n",
        "#pp.pprint(result.stdout)"
      ],
      "metadata": {
        "id": "_BkwD7jAN7yc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3420c2e5-1de6-4ca4-b63d-62c0929867a0"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('                     easy                 medium               hard                 extra                all                 \\n'\n",
            " 'count                250                  440                  174                  170                  1034                \\n'\n",
            " '=====================   EXECUTION ACCURACY     =====================\\n'\n",
            " 'execution            0.800                0.543                0.477                0.359                0.564               \\n'\n",
            " '\\n'\n",
            " '====================== EXACT MATCHING ACCURACY =====================\\n'\n",
            " 'exact match          0.772                0.382                0.339                0.059                0.416               \\n'\n",
            " '\\n'\n",
            " '---------------------PARTIAL MATCHING ACCURACY----------------------\\n'\n",
            " 'select               0.925                0.913                0.956                0.865                0.917               \\n'\n",
            " 'select(no AGG)       0.934                0.926                0.982                0.896                0.933               \\n'\n",
            " 'where                0.899                0.446                0.478                0.226                0.509               \\n'\n",
            " 'where(no OP)         0.919                0.451                0.543                0.357                0.551               \\n'\n",
            " 'group(no Having)     0.933                0.762                1.000                0.529                0.806               \\n'\n",
            " 'group                0.600                0.619                0.947                0.353                0.639               \\n'\n",
            " 'order                0.864                0.925                0.889                0.474                0.824               \\n'\n",
            " 'and/or               1.000                0.966                0.946                0.889                0.959               \\n'\n",
            " 'IUEN                 0.000                0.000                1.000                0.000                1.000               \\n'\n",
            " 'keywords             0.934                0.715                0.655                0.438                0.709               \\n'\n",
            " '---------------------- PARTIAL MATCHING RECALL ----------------------\\n'\n",
            " 'select               0.844                0.618                0.621                0.488                0.652               \\n'\n",
            " 'select(no AGG)       0.852                0.627                0.638                0.506                0.663               \\n'\n",
            " 'where                0.824                0.483                0.478                0.194                0.500               \\n'\n",
            " 'where(no OP)         0.843                0.489                0.543                0.306                0.542               \\n'\n",
            " 'group(no Having)     0.700                0.122                0.487                0.114                0.216               \\n'\n",
            " 'group                0.450                0.099                0.462                0.076                0.171               \\n'\n",
            " 'order                0.864                0.493                0.407                0.111                0.376               \\n'\n",
            " 'and/or               0.996                0.998                0.952                0.883                0.972               \\n'\n",
            " 'IUEN                 0.000                0.000                0.024                0.000                0.013               \\n'\n",
            " 'keywords             0.847                0.465                0.425                0.247                0.480               \\n'\n",
            " '---------------------- PARTIAL MATCHING F1 --------------------------\\n'\n",
            " 'select               0.883                0.737                0.753                0.624                0.762               \\n'\n",
            " 'select(no AGG)       0.891                0.748                0.774                0.647                0.776               \\n'\n",
            " 'where                0.860                0.464                0.478                0.209                0.504               \\n'\n",
            " 'where(no OP)         0.879                0.469                0.543                0.330                0.547               \\n'\n",
            " 'group(no Having)     0.800                0.211                0.655                0.187                0.340               \\n'\n",
            " 'group                0.514                0.171                0.621                0.125                0.270               \\n'\n",
            " 'order                0.864                0.643                0.558                0.180                0.516               \\n'\n",
            " 'and/or               0.998                0.981                0.949                0.886                0.966               \\n'\n",
            " 'IUEN                 1.000                1.000                0.047                1.000                0.025               \\n'\n",
            " 'keywords             0.888                0.564                0.516                0.316                0.573               \\n')\n"
          ]
        }
      ]
    }
  ]
}