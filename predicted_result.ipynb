{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roxyrong/w266_project/blob/main/predicted_result.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hfBv1xcVeVhc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FwsNiGo6IswG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57271faf-cf5d-4d99-f297-23b416c7b7d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount to Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdBuTgwrJCMN",
        "outputId": "39f23444-0b64-4f1a-8332-6f0cbd343658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Github/w266_project\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Github/w266_project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NNS3VTtjeStv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import collections\n",
        "import nltk\n",
        "import torch\n",
        "import subprocess\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN7VFp41d6V-",
        "outputId": "d1939373-c4d2-4c59-9bb9-6dd97c059a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:199: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n",
            "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"RoxyRong/t5_base_finetuned_final\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_0R7Nf_8e-F1"
      },
      "outputs": [],
      "source": [
        "# datasets\n",
        "with open('spider/train_spider.json', 'r') as f:\n",
        "    train_spider = pd.read_json(f)\n",
        "with open('spider/train_others.json', 'r') as f:\n",
        "    others_spider = pd.read_json(f)\n",
        "with open('spider/dev.json', 'r') as f:\n",
        "    dev_spider = pd.read_json(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cd1TZvOOfCJJ"
      },
      "outputs": [],
      "source": [
        "# load schema for all tables\n",
        "with open('spider/tables.json', 'r') as f:\n",
        "    schema_df = pd.read_json(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mvwBjfHdfEK1"
      },
      "outputs": [],
      "source": [
        "def _get_schema_string(table_json):\n",
        "  \"\"\"Returns the schema serialized as a string.\"\"\"\n",
        "  table_id_to_column_names = collections.defaultdict(list)\n",
        "  for table_id, name in table_json[\"column_names_original\"]:\n",
        "    table_id_to_column_names[table_id].append(name.lower())\n",
        "  tables = table_json[\"table_names_original\"]\n",
        "\n",
        "  table_strings = []\n",
        "  for table_id, table_name in enumerate(tables):\n",
        "    column_names = table_id_to_column_names[table_id]\n",
        "    table_string = \" | %s : %s\" % (table_name.lower(), \" , \".join(column_names))\n",
        "    table_strings.append(table_string)\n",
        "\n",
        "  return \"\".join(table_strings)\n",
        "\n",
        "schema_dict = {}\n",
        "for idx, row in schema_df.iterrows():\n",
        "  db_id = row['db_id']\n",
        "  schema = _get_schema_string(row)\n",
        "  schema_dict[db_id] = schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Jw93LLWlfExp"
      },
      "outputs": [],
      "source": [
        "# shuffle the dataset\n",
        "\n",
        "train_spider = train_spider.iloc[np.random.permutation(train_spider.index)].reset_index(drop=True)\n",
        "others_spider = train_spider.iloc[np.random.permutation(others_spider.index)].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zKJuMlejJbj8"
      },
      "outputs": [],
      "source": [
        "prefix = 'translate English to SQL:'\n",
        "\n",
        "train_spider['schema'] = train_spider['db_id'].map(schema_dict)\n",
        "train_spider['prompt'] = prefix + train_spider['question'] + '\\nDatabse schema is ' + train_spider['schema']\n",
        "others_spider['schema'] = others_spider['db_id'].map(schema_dict)\n",
        "others_spider['prompt'] = prefix + others_spider['question'] + '\\nDatabse schema is ' + others_spider['schema']\n",
        "dev_spider['schema'] = dev_spider['db_id'].map(schema_dict)\n",
        "dev_spider['prompt'] = prefix + dev_spider['question'] + '\\nDatabse schema is ' + dev_spider['schema']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIrk9u9MeJj1"
      },
      "outputs": [],
      "source": [
        "# evaluate\n",
        "max_length = 128\n",
        "\n",
        "for i in range(200, 1100, 100):\n",
        "  inputs = tokenizer.batch_encode_plus(\n",
        "          list(dev_spider.iloc[i:i+100]['prompt']),\n",
        "          max_length=max_length,\n",
        "          padding='max_length',\n",
        "          truncation=True,\n",
        "          return_attention_mask=True,\n",
        "          return_tensors='pt'\n",
        "      )\n",
        "\n",
        "  output_tokens = model.generate(\n",
        "      input_ids=inputs[\"input_ids\"],\n",
        "      attention_mask=inputs[\"attention_mask\"],\n",
        "      max_length=128,\n",
        "      num_beams=2,\n",
        "      early_stopping=True\n",
        "  )\n",
        "\n",
        "  outputs = [tokenizer.decode(i, skip_special_tokens=True) for i in output_tokens]\n",
        "\n",
        "  with open(predict_result_path, 'w') as f:\n",
        "    for idx, output in enumerate(outputs):\n",
        "        db_id = dev_spider.iloc[idx]['db_id']\n",
        "        f.write(output + '\\t' + db_id + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result_path = f'base_model/predicted_result_beam_search.txt'"
      ],
      "metadata": {
        "id": "aw18NDWNAvyu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ASgyUdBaeLFv"
      },
      "outputs": [],
      "source": [
        "with open(predict_result_path, 'w') as f:\n",
        "    for idx, output in enumerate(outputs):\n",
        "        db_id = dev_spider.iloc[idx]['db_id']\n",
        "        f.write(output + '\\t' + db_id + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuQq7WdGeM-0"
      },
      "outputs": [],
      "source": [
        "# evaluate results\n",
        "eval_path = f\"third_party/spider/evaluation.py\"\n",
        "gold = f\"third_party/spider/evaluation_examples/gold_example.txt\"\n",
        "pred = predict_result_path\n",
        "db_dir = f\"spider/database\"\n",
        "table = f\"spider/tables.json\"\n",
        "etype = \"all\"\n",
        "\n",
        "cmd_str = f\"python3 \\\"{eval_path}\\\" --gold \\\"{gold}\\\" --pred \\\"{pred}\\\" --db \\\"{db_dir}\\\" --table \\\"{table}\\\" --etype {etype} \"\n",
        "result = subprocess.run(cmd_str, shell=True, capture_output=True, text=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGD6pDbHeOi4"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "pprint.pprint(result.stdout[-4633:])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdHioNbqHy4n8VondisjW0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}