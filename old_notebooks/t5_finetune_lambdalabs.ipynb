{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/roxyrong/w266_project/blob/main/t5_finetune_text_to_sql.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rZJNzUdXJLqb"
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "!pip install accelerate -U\n",
    "!pip install datasets\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NrxT7ulwR19d"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "project_path = ''\n",
    "sys.path.append(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SPQuxy9_H0HP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict, List\n",
    "import subprocess\n",
    "import collections\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1cEvN9aDomCK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for evaluation\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bg4qdsH5JKX5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zva6eKoPH7j1"
   },
   "outputs": [],
   "source": [
    "# datasets\n",
    "with open('spider/train_spider.json', 'r') as f:\n",
    "    train_spider = pd.read_json(f)\n",
    "with open('spider/train_others.json', 'r') as f:\n",
    "    others_spider = pd.read_json(f)\n",
    "with open('spider/dev.json', 'r') as f:\n",
    "    dev_spider = pd.read_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3iYPW9ODH80T"
   },
   "outputs": [],
   "source": [
    "# load schema for all tables\n",
    "with open('spider/tables.json', 'r') as f:\n",
    "    schema_df = pd.read_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GE6FOe8wQ4QV"
   },
   "outputs": [],
   "source": [
    "def _get_schema_string(table_json):\n",
    "    \"\"\"Returns the schema serialized as a string.\"\"\"\n",
    "    table_id_to_column_names = collections.defaultdict(list)\n",
    "    for table_id, name in table_json[\"column_names_original\"]:\n",
    "        table_id_to_column_names[table_id].append(name.lower())\n",
    "        tables = table_json[\"table_names_original\"]\n",
    "\n",
    "    table_strings = []\n",
    "    for table_id, table_name in enumerate(tables):\n",
    "        column_names = table_id_to_column_names[table_id]\n",
    "        table_string = \" | %s : %s\" % (table_name.lower(), \" , \".join(column_names))\n",
    "        table_strings.append(table_string)\n",
    "\n",
    "    return \"\".join(table_strings)\n",
    "\n",
    "schema_dict = {}\n",
    "for idx, row in schema_df.iterrows():\n",
    "    db_id = row['db_id']\n",
    "    schema = _get_schema_string(row)\n",
    "    schema_dict[db_id] = schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gZPZvrTWH-LC"
   },
   "outputs": [],
   "source": [
    "# shuffle the dataset\n",
    "\n",
    "train_spider = train_spider.iloc[np.random.permutation(train_spider.index)].reset_index(drop=True)\n",
    "others_spider = train_spider.iloc[np.random.permutation(others_spider.index)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ja3AjYzL0Ao"
   },
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "an2hxxSuH_6g"
   },
   "outputs": [],
   "source": [
    "# construct prompt\n",
    "\n",
    "prefix = 'translate English to SQL:'\n",
    "\n",
    "train_spider['schema'] = train_spider['db_id'].map(schema_dict)\n",
    "train_spider['prompt'] = prefix + train_spider['question'] + '\\nDatabse schema is ' + train_spider['schema']\n",
    "others_spider['schema'] = others_spider['db_id'].map(schema_dict)\n",
    "others_spider['prompt'] = prefix + others_spider['question'] + '\\nDatabse schema is ' + others_spider['schema']\n",
    "dev_spider['schema'] = dev_spider['db_id'].map(schema_dict)\n",
    "dev_spider['prompt'] = prefix + dev_spider['question'] + '\\nDatabse schema is ' + dev_spider['schema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hizv4iaEIg1T"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(text_pair, tokenizer, max_length=128):\n",
    "    orig_text, target_text = text_pair\n",
    "    orig_encoded = tokenizer.batch_encode_plus(\n",
    "        [orig_text],\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    orig_input_ids = orig_encoded['input_ids'][0]\n",
    "    orig_attention_mask = orig_encoded['attention_mask'][0]\n",
    "\n",
    "    target_encoded = tokenizer.batch_encode_plus(\n",
    "        [target_text],\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    label_ids = target_encoded['input_ids'][0]\n",
    "\n",
    "    return {'input_ids': orig_input_ids,\n",
    "            'attention_mask': orig_attention_mask,\n",
    "            'labels': label_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_9IiV9LXIkkD"
   },
   "outputs": [],
   "source": [
    "class TranslationDataIterator:\n",
    "\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 tokenizer,\n",
    "                 max_load_at_once,\n",
    "                 max_length=128,\n",
    "                 shuffle=True):\n",
    "\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.n_examples = len(df)\n",
    "        self.max_load_at_once = max_load_at_once\n",
    "        self.max_length = max_length\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # Initialize row order, call on_epoch_end to shuffle row indices\n",
    "        self.row_order = np.arange(1, self.n_examples+1)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "        # Load first chunk of max_load_at_once examples\n",
    "        self.df_curr_loaded = self._load_next_chunk(0)\n",
    "        self.curr_idx_in_load = 0\n",
    "\n",
    "    def _load_next_chunk(self, idx):\n",
    "        load_start = idx\n",
    "        load_end = idx + self.max_load_at_once\n",
    "\n",
    "        # Indices to skip are the ones in the shuffled row_order before and\n",
    "        # after the chunk we'll use for this chunk\n",
    "        self.df_curr_loaded = self.df.iloc[load_start:load_end].sample(frac=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_examples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.df_curr_loaded is None or self.curr_idx_in_load >= len(self.df_curr_loaded):\n",
    "            self._load_next_chunk(idx)\n",
    "            self.curr_idx_in_load = 0\n",
    "\n",
    "        text_pair = self.df_curr_loaded[['prompt', 'query']].values.astype(str)[self.curr_idx_in_load]\n",
    "        self.curr_idx_in_load += 1\n",
    "\n",
    "        item_data = preprocess_data(\n",
    "            text_pair,\n",
    "            self.tokenizer,\n",
    "            self.max_length\n",
    "        )\n",
    "\n",
    "        return item_data\n",
    "\n",
    "    def __call__(self):\n",
    "        for i in range(self.__len__()):\n",
    "            yield self.__getitem__(i)\n",
    "\n",
    "            if i == self.__len__()-1:\n",
    "                self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.row_order = list(np.random.permutation(self.row_order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmEu_mBcL8zW"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ArkzDDRD4u2H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_path: results/t5-base_fine_tuned_1\n",
      "model_path: results/t5-base_fine_tuned_1/t5-base_fine_tuned_1\n",
      "result_path: results/t5-base_fine_tuned_1/predicted_result_checkpoint-2000_1.txt\n"
     ]
    }
   ],
   "source": [
    "model_name = \"t5-base\"\n",
    "technique = \"fine_tuned\"\n",
    "version = 1\n",
    "checkpoint = \"checkpoint-3504\"\n",
    "inference_model = \"checkpoint-2000\"\n",
    "\n",
    "folder_name = f\"{model_name}_{technique}_{version}\"\n",
    "train_path = f\"results/{folder_name}\"\n",
    "model_path = train_path + f'/{folder_name}'\n",
    "last_check_point = train_path + f'/checkpoint-2190'\n",
    "result_path = f'results/{folder_name}/predicted_result_{inference_model}_{version}.txt'\n",
    "\n",
    "\n",
    "print(\"train_path:\", train_path)\n",
    "print(\"model_path:\", model_path)\n",
    "print(\"result_path:\", result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "U2FgTQubLjp9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gZ4pWEZ8ImOU"
   },
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "max_load_at_once = 100\n",
    "\n",
    "train_data_iterator = TranslationDataIterator(\n",
    "    df=train_spider,\n",
    "    tokenizer=tokenizer,\n",
    "    max_load_at_once=max_load_at_once,\n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "valid_data_iterator = TranslationDataIterator(\n",
    "    df=others_spider,\n",
    "    tokenizer=tokenizer,\n",
    "    max_load_at_once=max_load_at_once,\n",
    "    max_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "d7r9oQcVInfU"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    train_path,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "fWGwZQFhIo0_"
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_data_iterator,\n",
    "    eval_dataset=valid_data_iterator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "gr-QshK9IqBj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2190' max='2190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2190/2190 : < :, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2190, training_loss=0.0, metrics={'train_runtime': 0.2704, 'train_samples_per_second': 129454.855, 'train_steps_per_second': 8100.175, 'total_flos': 2.13135261696e+16, 'train_loss': 0.0, 'epoch': 5.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start from scratch\n",
    "# trainer.train()\n",
    "\n",
    "# start from a checkpoint\n",
    "trainer.train(resume_from_checkpoint= last_check_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "iz6CbDO2Vd6k"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='104' max='104' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [104/104 00:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0003102949121966958,\n",
       " 'eval_runtime': 33.9338,\n",
       " 'eval_samples_per_second': 48.889,\n",
       " 'eval_steps_per_second': 3.065,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8261ad7b218f463a9c3a9951003628d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/RoxyRong/t5_base_finetuned/commit/82cf2e2b975deb40df4f8aa94737ae1c44c05c18', commit_message='Upload T5ForConditionalGeneration', commit_description='', oid='82cf2e2b975deb40df4f8aa94737ae1c44c05c18', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"RoxyRong/t5_base_finetuned\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Cp4TIpG27hA"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "QwK5m6fAZ_vM"
   },
   "outputs": [],
   "source": [
    "finetune_model = T5ForConditionalGeneration.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4perd2zXmzG"
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "max_length = 512\n",
    "\n",
    "inputs = tokenizer.batch_encode_plus(\n",
    "        list(dev_spider['prompt']),\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "output_tokens = finetune_model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "outputs = [tokenizer.decode(i, skip_special_tokens=True) for i in output_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3r5R4IuOgI7r"
   },
   "outputs": [],
   "source": [
    "with open(result_path, 'w') as f:\n",
    "    for idx, output in enumerate(outputs):\n",
    "        db_id = dev_spider.iloc[idx]['db_id']\n",
    "        f.write(output + '\\t' + db_id + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nv7ZpIoaajtw"
   },
   "outputs": [],
   "source": [
    "# evaluate results\n",
    "eval_path = f\"third_party/spider/evaluation.py\"\n",
    "gold = f\"third_party/spider/evaluation_examples/gold_example.txt\"\n",
    "pred = result_path\n",
    "db_dir = f\"spider/database\"\n",
    "table = f\"spider/tables.json\"\n",
    "etype = \"all\"\n",
    "\n",
    "cmd_str = f\"python3 \\\"{eval_path}\\\" --gold \\\"{gold}\\\" --pred \\\"{pred}\\\" --db \\\"{db_dir}\\\" --table \\\"{table}\\\" --etype {etype} \"\n",
    "result = subprocess.run(cmd_str, shell=True, capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hh4yyml1jMbY"
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(result.stdout[-4633:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
