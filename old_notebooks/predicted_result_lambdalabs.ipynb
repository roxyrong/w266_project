{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/roxyrong/w266_project/blob/main/predicted_result.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hfBv1xcVeVhc"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "!pip install accelerate -U\n",
    "!pip install nltk\n",
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdBuTgwrJCMN",
    "outputId": "39f23444-0b64-4f1a-8332-6f0cbd343658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT_J_Baseline.ipynb               spider.py\n",
      "README.md                          spider.zip\n",
      "model_upload.ipynb                 t5_base.ipynb\n",
      "predicted_result.ipynb             t5_finetune_lambdalabs.ipynb\n",
      "predicted_result_lambdalabs.ipynb  t5_finetune_text_to_sql.ipynb\n",
      "project_setup.ipynb                t5_soft_prompt_tuning_lambdalabs.ipynb\n",
      "project_setup_lambdalabs.ipynb     t5_soft_prompt_tuning_text_to_sql.ipynb\n",
      "\u001b[0m\u001b[01;34mresults\u001b[0m/                           \u001b[01;34mthird_party\u001b[0m/\n",
      "\u001b[01;34mspider\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NNS3VTtjeStv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import nltk\n",
    "import torch\n",
    "import subprocess\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from peft import PeftConfig, PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WN7VFp41d6V-",
    "outputId": "d1939373-c4d2-4c59-9bb9-6dd97c059a8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84476da56f6547d09d825a647204db9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6dbc3e884524a90815c6339e7315fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84ff20b09334ab8bfe189a1f94f1bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# finetuned version\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\", model_max_length=128)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"RoxyRong/t5_base_finetuned_15_epochs\").to(\"cuda\")\n",
    "predict_result_path = f'results/predicted_result_t5_base_finetuned_15_epochs.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft prompt tuning version\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"t5-base\", model_max_length=128)\n",
    "# peft_model_id = \"RoxyRong/t5_base_soft_prompt_2_10epochs\"\n",
    "# config = PeftConfig.from_pretrained(peft_model_id)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"RoxyRong/t5_base_finetuned_2\")\n",
    "# model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "# model = model.to(\"cuda\")\n",
    "# predict_result_path = f'base_model/predicted_result_t5_base_soft_prompt_2_10epochs.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_0R7Nf_8e-F1"
   },
   "outputs": [],
   "source": [
    "# datasets\n",
    "with open('spider/train_spider.json', 'r') as f:\n",
    "    train_spider = pd.read_json(f)\n",
    "with open('spider/train_others.json', 'r') as f:\n",
    "    others_spider = pd.read_json(f)\n",
    "with open('spider/dev.json', 'r') as f:\n",
    "    dev_spider = pd.read_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cd1TZvOOfCJJ"
   },
   "outputs": [],
   "source": [
    "# load schema for all tables\n",
    "with open('spider/tables.json', 'r') as f:\n",
    "    schema_df = pd.read_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mvwBjfHdfEK1"
   },
   "outputs": [],
   "source": [
    "def _get_schema_string(table_json):\n",
    "    \"\"\"Returns the schema serialized as a string.\"\"\"\n",
    "    table_id_to_column_names = collections.defaultdict(list)\n",
    "    for table_id, name in table_json[\"column_names_original\"]:\n",
    "        table_id_to_column_names[table_id].append(name.lower())\n",
    "        tables = table_json[\"table_names_original\"]\n",
    "\n",
    "    table_strings = []\n",
    "    for table_id, table_name in enumerate(tables):\n",
    "        column_names = table_id_to_column_names[table_id]\n",
    "        table_string = \" | %s : %s\" % (table_name.lower(), \" , \".join(column_names))\n",
    "        table_strings.append(table_string)\n",
    "\n",
    "    return \"\".join(table_strings)\n",
    "\n",
    "schema_dict = {}\n",
    "for idx, row in schema_df.iterrows():\n",
    "    db_id = row['db_id']\n",
    "    schema = _get_schema_string(row)\n",
    "    schema_dict[db_id] = schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Jw93LLWlfExp"
   },
   "outputs": [],
   "source": [
    "# shuffle the dataset\n",
    "\n",
    "train_spider = train_spider.iloc[np.random.permutation(train_spider.index)].reset_index(drop=True)\n",
    "others_spider = train_spider.iloc[np.random.permutation(others_spider.index)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zKJuMlejJbj8"
   },
   "outputs": [],
   "source": [
    "prefix = 'translate English to SQL:'\n",
    "\n",
    "train_spider['schema'] = train_spider['db_id'].map(schema_dict)\n",
    "train_spider['prompt'] = prefix + train_spider['question'] + '\\nDatabse schema is ' + train_spider['schema']\n",
    "others_spider['schema'] = others_spider['db_id'].map(schema_dict)\n",
    "others_spider['prompt'] = prefix + others_spider['question'] + '\\nDatabse schema is ' + others_spider['schema']\n",
    "dev_spider['schema'] = dev_spider['db_id'].map(schema_dict)\n",
    "dev_spider['prompt'] = prefix + dev_spider['question'] + '\\nDatabse schema is ' + dev_spider['schema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nIrk9u9MeJj1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "max_length = 128\n",
    "step = 100\n",
    "\n",
    "for i in range(0, 1100, step):\n",
    "    print(i)\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "          list(dev_spider.iloc[i:i+step]['prompt']),\n",
    "          max_length=max_length,\n",
    "          padding='max_length',\n",
    "          truncation=True,\n",
    "          return_attention_mask=True,\n",
    "          return_tensors='pt'\n",
    "      )\n",
    "    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "    output_tokens = model.generate(\n",
    "      input_ids=inputs[\"input_ids\"],\n",
    "      attention_mask=inputs[\"attention_mask\"],\n",
    "      max_length=128\n",
    "    )\n",
    "\n",
    "    outputs = [tokenizer.decode(i, skip_special_tokens=True) for i in output_tokens]\n",
    "\n",
    "    with open(predict_result_path, 'a', encoding='utf-8') as f:\n",
    "        for idx, output in enumerate(outputs):\n",
    "            db_id = dev_spider.iloc[idx]['db_id']\n",
    "            f.write(output + '\\t' + db_id + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kuQq7WdGeM-0"
   },
   "outputs": [],
   "source": [
    "# evaluate results\n",
    "# predict_result_path = f'base_model/predicted_result_t5_base_soft_prompt_2.txt'\n",
    "\n",
    "eval_path = f\"third_party/spider/evaluation.py\"\n",
    "gold = f\"third_party/spider/evaluation_examples/gold_example.txt\"\n",
    "pred = predict_result_path\n",
    "db_dir = f\"spider/database\"\n",
    "table = f\"spider/tables.json\"\n",
    "etype = \"all\"\n",
    "\n",
    "cmd_str = f\"python3 \\\"{eval_path}\\\" --gold \\\"{gold}\\\" --pred \\\"{pred}\\\" --db \\\"{db_dir}\\\" --table \\\"{table}\\\" --etype {etype} \"\n",
    "result = subprocess.run(cmd_str, shell=True, capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oGD6pDbHeOi4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('                     easy                 medium               '\n",
      " 'hard                 extra                all                 \\n'\n",
      " 'count                250                  440                  '\n",
      " '174                  170                  1034                \\n'\n",
      " '=====================   EXECUTION ACCURACY     =====================\\n'\n",
      " 'execution            0.604                0.386                '\n",
      " '0.316                0.141                0.387               \\n'\n",
      " '\\n'\n",
      " '====================== EXACT MATCHING ACCURACY =====================\\n'\n",
      " 'exact match          0.644                0.368                '\n",
      " '0.287                0.124                0.381               \\n'\n",
      " '\\n'\n",
      " '---------------------PARTIAL MATCHING ACCURACY----------------------\\n'\n",
      " 'select               0.951                0.903                '\n",
      " '0.974                0.953                0.935               \\n'\n",
      " 'select(no AGG)       0.967                0.917                '\n",
      " '0.974                0.953                0.946               \\n'\n",
      " 'where                0.857                0.825                '\n",
      " '0.529                0.571                0.764               \\n'\n",
      " 'where(no OP)         0.870                0.825                '\n",
      " '0.588                0.857                0.807               \\n'\n",
      " 'group(no Having)     0.867                0.924                '\n",
      " '0.833                0.875                0.889               \\n'\n",
      " 'group                0.867                0.924                '\n",
      " '0.800                0.875                0.881               \\n'\n",
      " 'order                0.850                0.800                '\n",
      " '0.906                0.958                0.868               \\n'\n",
      " 'and/or               1.000                0.950                '\n",
      " '0.901                0.882                0.943               \\n'\n",
      " 'IUEN                 0.000                0.000                '\n",
      " '0.462                0.667                0.471               \\n'\n",
      " 'keywords             0.937                0.956                '\n",
      " '0.846                0.907                0.925               \\n'\n",
      " '---------------------- PARTIAL MATCHING RECALL ----------------------\\n'\n",
      " 'select               0.696                0.445                '\n",
      " '0.437                0.241                0.471               \\n'\n",
      " 'select(no AGG)       0.708                0.452                '\n",
      " '0.437                0.241                0.477               \\n'\n",
      " 'where                0.611                0.371                '\n",
      " '0.196                0.122                0.340               \\n'\n",
      " 'where(no OP)         0.620                0.371                '\n",
      " '0.217                0.184                0.359               \\n'\n",
      " 'group(no Having)     0.650                0.466                '\n",
      " '0.641                0.266                0.446               \\n'\n",
      " 'group                0.650                0.466                '\n",
      " '0.615                0.266                0.442               \\n'\n",
      " 'order                0.773                0.480                '\n",
      " '0.492                0.284                0.443               \\n'\n",
      " 'and/or               1.000                0.998                '\n",
      " '0.981                1.000                0.996               \\n'\n",
      " 'IUEN                 0.000                0.000                '\n",
      " '0.143                0.056                0.103               \\n'\n",
      " 'keywords             0.693                0.470                '\n",
      " '0.379                0.229                0.443               \\n'\n",
      " '---------------------- PARTIAL MATCHING F1 --------------------------\\n'\n",
      " 'select               0.804                0.597                '\n",
      " '0.603                0.385                0.626               \\n'\n",
      " 'select(no AGG)       0.818                0.606                '\n",
      " '0.603                0.385                0.634               \\n'\n",
      " 'where                0.714                0.512                '\n",
      " '0.286                0.202                0.471               \\n'\n",
      " 'where(no OP)         0.724                0.512                '\n",
      " '0.317                0.303                0.497               \\n'\n",
      " 'group(no Having)     0.743                0.619                '\n",
      " '0.725                0.408                0.594               \\n'\n",
      " 'group                0.743                0.619                '\n",
      " '0.696                0.408                0.589               \\n'\n",
      " 'order                0.810                0.600                '\n",
      " '0.637                0.438                0.587               \\n'\n",
      " 'and/or               1.000                0.973                '\n",
      " '0.939                0.938                0.969               \\n'\n",
      " 'IUEN                 1.000                1.000                '\n",
      " '0.218                0.103                0.168               \\n'\n",
      " 'keywords             0.797                0.631                '\n",
      " '0.524                0.366                0.600               \\n')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(result.stdout[-4633:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPdHioNbqHy4n8VondisjW0",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
