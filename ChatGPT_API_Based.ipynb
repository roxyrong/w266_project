{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnQuvIlwyqqD3apxIGmpoc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roxyrong/w266_project/blob/main/ChatGPT_API_Based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChatGPT API-based SQL Generation\n",
        "\n"
      ],
      "metadata": {
        "id": "3x-_mwoxHqj2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PhIQT8JHpa6",
        "outputId": "a9c36ad5-1957-4c4c-83df-b260439df2de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: panel in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: bokeh<3.3.0,>=3.1.1 in /usr/local/lib/python3.10/dist-packages (from panel) (3.1.1)\n",
            "Requirement already satisfied: param>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from panel) (1.13.0)\n",
            "Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.10/dist-packages (from panel) (2.3.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from panel) (2023.7.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel) (3.0.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel) (2.0.2)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from panel) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from panel) (4.65.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel) (6.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from panel) (4.7.1)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from panel) (1.5.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh<3.3.0,>=3.1.1->panel) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh<3.3.0,>=3.1.1->panel) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from bokeh<3.3.0,>=3.1.1->panel) (1.22.4)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh<3.3.0,>=3.1.1->panel) (23.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh<3.3.0,>=3.1.1->panel) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh<3.3.0,>=3.1.1->panel) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh<3.3.0,>=3.1.1->panel) (6.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->panel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->panel) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bleach->panel) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel) (1.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel) (0.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->panel) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->panel) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->panel) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->panel) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh<3.3.0,>=3.1.1->panel) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "# Set up openai\n",
        "!pip install openai\n",
        "import openai\n",
        "openai.api_key=\"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\"\n",
        "\n",
        "# In case we want user interaction\n",
        "!pip install panel\n",
        "import panel as pn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up google drive for Spider\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N5dXtaOMjyo",
        "outputId": "599d958b-8454-4526-e82e-584acc59e445"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Github/w266_project\n",
        "\n",
        "import sys\n",
        "project_path = '/content/drive/MyDrive/Github/w266_project'\n",
        "sys.path.append(project_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-8LeLnnMsvH",
        "outputId": "0b68f067-9ae8-4d22-85bf-cbe33ab179fd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Github/w266_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional useful imports\n",
        "import os\n",
        "from typing import Dict, List\n",
        "import subprocess\n",
        "import collections\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk"
      ],
      "metadata": {
        "id": "6-libl2-MxHU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for evaluation\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuJDcI8PM6WM",
        "outputId": "218286de-e8f2-40aa-c14d-bca5fafc2759"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Spider Data"
      ],
      "metadata": {
        "id": "RtRiqJoeNEak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Spider datasets\n",
        "with open('spider/train_spider.json', 'r') as f:\n",
        "    train_spider = pd.read_json(f)\n",
        "with open('spider/train_others.json', 'r') as f:\n",
        "    others_spider = pd.read_json(f)\n",
        "with open('spider/dev.json', 'r') as f:\n",
        "    dev_spider = pd.read_json(f)"
      ],
      "metadata": {
        "id": "kJND7UQuNHGQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load schema for all tables\n",
        "with open('spider/tables.json', 'r') as f:\n",
        "    schema_df = pd.read_json(f)"
      ],
      "metadata": {
        "id": "Xw7qyNIcNUJG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Function to extract target schemas from Spider json to a dict\n",
        "# for training and prompt usage.\n",
        "def _get_schema_string(table_json):\n",
        "    \"\"\"Returns the schema serialized as a string.\"\"\"\n",
        "    table_id_to_column_names = collections.defaultdict(list)\n",
        "    for table_id, name in table_json[\"column_names_original\"]:\n",
        "        table_id_to_column_names[table_id].append(name.lower())\n",
        "        tables = table_json[\"table_names_original\"]\n",
        "\n",
        "    table_strings = []\n",
        "    for table_id, table_name in enumerate(tables):\n",
        "        column_names = table_id_to_column_names[table_id]\n",
        "        table_string = \" | %s : %s\" % (table_name.lower(), \" , \".join(column_names))\n",
        "        table_strings.append(table_string)\n",
        "\n",
        "    return \"\".join(table_strings)\n",
        "\n",
        "schema_dict = {}\n",
        "for idx, row in schema_df.iterrows():\n",
        "    db_id = row['db_id']\n",
        "    schema = _get_schema_string(row)\n",
        "    schema_dict[db_id] = schema"
      ],
      "metadata": {
        "id": "fKQchoklNWtW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up GPT API"
      ],
      "metadata": {
        "id": "4jF82LuZNJt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to call GPT API\n",
        "def text_to_sql(messages, temperature=0):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "vNZTlyPHHvTY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with single prompt"
      ],
      "metadata": {
        "id": "hgRBgORtNN-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test prompt\n",
        "context = [ {'role':'system', 'content':\"\"\"\n",
        "Parse the question provided into SQL based on a provided schema which describes a database schema.\n",
        "Based on the provided schema, create an ANSI-92 SQL Query to answer the provided\n",
        "Return the answer as a SQL query ONLY. Do not include any additional explanation.\"\n",
        "\"\"\"} ]\n",
        "\n",
        "\n",
        "context.append( {'role':'system', 'content':\"\"\"\n",
        "Schema: | department : department_id , name , creation , ranking , budget_in_billions , num_employees | head : head_id , name , born_state , age | management : department_id , head_id , temporary_acting\n",
        "\"\"\"})\n",
        "\n",
        "context.append({'role':'user', 'content':\"Question:How many heads of the departments are older than 56?\"})\n",
        "\n"
      ],
      "metadata": {
        "id": "_dVxg8GxIOFs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ9k0cqEJCJP",
        "outputId": "c549dea1-14ec-4866-f8cd-f844d8364455"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': '\\nParse the question provided into SQL based on a provided schema which describes a database schema.\\nBased on the provided schema, create an ANSI-92 SQL Query to answer the provided\\nReturn the answer as a SQL query ONLY. Do not include any additional explanation.\"\\n'}, {'role': 'system', 'content': '\\nSchema: | department : department_id , name , creation , ranking , budget_in_billions , num_employees | head : head_id , name , born_state , age | management : department_id , head_id , temporary_acting\\n'}, {'role': 'user', 'content': 'Question:How many heads of the departments are older than 56?'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = text_to_sql(context)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mSKqTt2Ktsm",
        "outputId": "c9e6d5f6-018a-4f64-caeb-d2b63ca5f0cd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT COUNT(*) FROM head WHERE age > 56;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build prompt library for baseline test"
      ],
      "metadata": {
        "id": "I89BYrOyNjgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ToDo - build instruction based prompts"
      ],
      "metadata": {
        "id": "_56XXmYSLzEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run test on dev data set"
      ],
      "metadata": {
        "id": "Vu_NtIMQNn73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ToDo - figure out how to do batch inference and manage API rate limiting"
      ],
      "metadata": {
        "id": "d7_YNS35Nqte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "kye_AT7VNsaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model output to Drive\n",
        "model_name = \"GPT-3.5-turbo\"\n",
        "technique = \"pretrained\"\n",
        "version = 1\n",
        "inference_model = \"GPT-3.5-turbo\"\n",
        "\n",
        "folder_name = f\"{model_name}_{technique}_{version}\"\n",
        "# train_path = f\"results/{folder_name}\"\n",
        "# model_path = train_path + f'/{folder_name}'\n",
        "# last_check_point = train_path + f'/checkpoint-2190'\n",
        "result_path = f'results/{folder_name}/predicted_result_{inference_model}_{version}.txt'\n",
        "\n",
        "\n",
        "# print(\"train_path:\", train_path)\n",
        "# print(\"model_path:\", model_path)\n",
        "print(\"result_path:\", result_path)\n",
        "\n",
        "with open(result_path, 'w', encoding='utf-8') as f:\n",
        "    for idx, output in enumerate(outputs):\n",
        "        db_id = dev_spider.iloc[idx]['db_id']\n",
        "        f.write(output + '\\t' + db_id + '\\n')"
      ],
      "metadata": {
        "id": "oFpkUIcONumR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate results\n",
        "eval_path = f\"third_party/spider/evaluation.py\"\n",
        "gold = f\"third_party/spider/evaluation_examples/gold_example.txt\"\n",
        "#pred = f\"results/GPT-J_pretrained_1/predicted_result_GPT-J-standard_1_clean.txt\"\n",
        "db_dir = f\"spider/database\"\n",
        "table = f\"spider/tables.json\"\n",
        "etype = \"all\"\n",
        "\n",
        "cmd_str = f\"python3 \\\"{eval_path}\\\" --gold \\\"{gold}\\\" --pred \\\"{pred}\\\" --db \\\"{db_dir}\\\" --table \\\"{table}\\\" --etype {etype} \"\n",
        "result = subprocess.run(cmd_str, shell=True, capture_output=True, text=True)"
      ],
      "metadata": {
        "id": "tb4XSqXeN54T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print results\n",
        "pp = pprint.PrettyPrinter(width=160)\n",
        "pp.pprint(result.stdout[-4633:])\n",
        "#pp.pprint(result.stdout)"
      ],
      "metadata": {
        "id": "_BkwD7jAN7yc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}